import gym
from DeepNet import Agent
import numpy as np

if __name__ == '__main__':
    env = gym.make('LunarLander-v2')
    Agent = Agent(gamma = 0.99, lr=0.003, epsilon =1.0, input_dim=[8], n_actions=4,
                 batch_size = 64)
    
    # score & epsilon history
    score_hist, eps_hist = [], []
    
    n_games = 500
    
    for i in range (n_games):
        score = 0
        terminated = False
        obs = env.reset()
        
        while not terminated:
            action = Agent.choose_action(obs)
            new_obs, reward, terminated, _ = env.step(action)
            
            # increment score
            score += reward
            # store in mem
            Agent.store_transition(obs, new_obs, action, reward, terminated)
            # learn
            Agent.learn()
            # iterate
            obs = new_obs
        score_hist.append(score)
        eps_hist.append(Agent.epsilon)
        
        # average acore
        avg_score = np.mean(score_hist[-100:])
        
        print('episode ',i,' score %.2f'%score, 'average score %.2f'%avg_score,
              'epsilon %.2f'%Agent.epsilon)
        
# plot learning curve
import matplotlib.pyplot as plt

x = [i+1 for i in range (n_games)]
plt.plot(x, score_hist, 'b', x, eps_hist, 'g')